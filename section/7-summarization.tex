
\chapter{总结与展望}
\label{sec:summary}

\section{工作总结}
近年来，深度学习技术成为了人工智能领域发展最快的分支之一。
得益于大数据时代的爆发式数据增长，深度神经网络模型可以获得海量高质量训练数据。
深度学习广泛应用在不同的领域中，并取得了成功。
然而随着深度神经网络模型性能的提高，模型的复杂度和参数量也迅速增长，导致单个计算设备无法训练完整的模型，因此为了对大模型进行训练，将模型划分到多个设备上进行并行化训练的模型并行化技术出现。

进行模型并行化训练需要对模型进行合理的划分，目前流行的深度学习框架PyTorch中，仍然依赖使用者对模型进行手动划分。
而对于大型神经网络模型来说，由于模型规模大，手动划分十分困难。
因此一些自动化的模型划分方法被提出，但是现有的方法仍然存在一些问题，例如没有在模型划分的过程中考虑底层硬件环境特点，模型划分粒度较粗，没有对模型训练过程进行精确建模等。

针对上述问题，为了更好的提供模型的自动划分和大模型的训练功能，本文提出并实现了一种针对大型神经网络的训练框架：\sys{}。
\sys{}基于PyTorch实现，并且可以接受通用的PyTorch神经网络模型。
对于输入的模型，\sys{}首先解析模型底层的计算图，并将其转化为一种中间表示。
然后对于计算图，\sys{}通过动态分析和静态分析的方式，获取图中每个节点的计算时间和内存用量等模型元信息。
同时，\sys{}也会采集底层硬件信息，获取设备之间的通信代价模型。
\sys{}将依据模型元信息和硬件信息，以提升训练效率为目标，对模型进行划分，然后将划分后的模型放置到设备上进行训练。
具体贡献包括：
\begin{enumerate}
	\item 实现了自动化的模型分析方法：由于PyTorch中的计算图在运行时动态生成，因此PyTorch的模型难以进行静态分析和划分。我们设计了模型转换模块，可以完成PyTorch模型和计算图中间表示的双向转换。并基于模型转换模块实现了自动化的模型分析，提取出对于模型划分有帮助的模型元信息。
	\item 实现了对底层设备之间通信的建模：参与模型并行化训练的多个设备之间需要进行通信，而在集群中，设备之间的通信方式往往是异构的。结合底层设备之间通信的异构性有助于得到更好的划分效果。我们设计了通信建模模块，可以对底层设备之间的通信进行建模。
	\item 实现了基于约束优化求解的模型划分方法：\sys{}形式化的定义了模型划分问题，使用基于约束优化求解的方法，以最小化单次迭代时间为目标，进行约束求解。相比于现有方法，\sys{}中的约束求解考虑了反向传播的代价，并且对底层的通信进行了更精确的描述。
	\item 通过实验对\sys{} 进行了验证：我们在真实的数据集和模型上对比了\sys{}和其他的模型划分方法，实验结果验证了\sys{}可以有效提升大模型进行模型并行化训练的训练效率，缩短模型训练用时，同时不会影响模型训练过程的收敛性。
\end{enumerate}


\section{工作展望}

本文中提出的模型并行化训练框架\sys{}，简化大模型的模型并行化训练过程，有效提升大模型的训练效率，
但是仍然有需要进一步改进的方向。

本文中对于模型的分析采用了动态分析和静态分析结合的方式，对于模型静态图中各个节点的显存占用使用了静态分析，而对于每个节点的前向传播和反向传播时间使用了动态分析。
相比于静态分析，动态分析需要获取运行时的信息，因此需要一些额外的时间代价。
尽管这一部分代价和模型训练用时比起来几乎可以忽略，但是我们仍然希望使用静态分析替代动态分析，来避免这一部分的代价。
因此，未来的工作中会改善模型分析的用时，尝试为不同算子构建计算用时预测模型，通过计算用时预测模型对模型计算图进行静态分析，从而减少模型分析的代价。

在实验验证方面，我们采用单机多设备的实验环境，和真实的多机多设备的实验环境仍有一定差距。在模型和数据集的选择上，我们选择来自图像领域的模型和数据集。在未来的工作中，我们会在更真实的场景下进行实验，并且增加对文本、音频、视频等领域模型和数据集的评估，增强实验结果的有效性。